{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Building Ranger Random Forest Models 1 or 2\r\n",
    "# Author: David Gray Lassiter, PhD\r\n",
    "# Date: 2020-sep-22\r\n",
    "# Version:\r\n",
    "\r\n",
    "# Inspired by:\r\n",
    "# https://juliasilge.com/blog/sf-trees-random-tuning/\r\n",
    "# https://juliasilge.com/blog/xgboost-tune-volleyball/\r\n",
    "# https://juliasilge.com/blog/wind-turbine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 Ensure all pkgs in this script are installed ####\r\n",
    "install.packages(\"here\")\r\n",
    "install.packages(\"tidymodels\")\r\n",
    "install.packages(\"ranger\")\r\n",
    "install.packages(\"xgboost\")\r\n",
    "install.packages(\"doParallel\")\r\n",
    "install.packages(\"vip\")\r\n",
    "\r\n",
    "library(\"here\")\r\n",
    "library(\"tidymodels\")\r\n",
    "library(\"ranger\")\r\n",
    "library(\"xgboost\")\r\n",
    "library(\"doParallel\")\r\n",
    "library(\"vip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 Load data ####\r\n",
    "setwd(here())\r\n",
    "\r\n",
    "importPath <- \"07_outputs/06_dataForModel1and2/\"\r\n",
    "\r\n",
    "originalExportPath <- \"07_outputs/07_buildingModel1and2/01_localExportData/\"\r\n",
    "\r\n",
    "exportPath <- originalExportPath\r\n",
    "\r\n",
    "allDataForModel1and2 <- readRDS(paste0(importPath, \"allDataForModel1and2\"))\r\n",
    "\r\n",
    "selectedPredictorVarsDataForModel1and2 <-\r\n",
    "    readRDS(paste0(importPath, \"selectedPredictorVarsDataForModel1and2\"))\r\n",
    "\r\n",
    "# 03 load latest var lists ####\r\n",
    "outcomeVarModel1and2 <- readRDS(paste0(importPath, \"outcomeVarModel1and2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04 My save function ####\r\n",
    "# I define the function in place in case I move this script to the cloud\r\n",
    "# and will not be able to refer to local functions\r\n",
    "mySave <- function(object) {\r\n",
    "    objectName <- deparse(substitute(object))\r\n",
    "\r\n",
    "    saveRDS(\r\n",
    "        object,\r\n",
    "        paste0(exportPath, objectName)\r\n",
    "    )\r\n",
    "}\r\n",
    "\r\n",
    "testSave <- 1 + 1\r\n",
    "\r\n",
    "mySave(testSave)\r\n",
    "\r\n",
    "rm(testSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 Set parameters for model-building ####\r\n",
    "modelVersions <- c(1, 2)\r\n",
    "\r\n",
    "datasets <- c(\"SelectedVars\", \"ALL\")\r\n",
    "\r\n",
    "recordsShrinkFactors <- c(100, 50, 25, 12, 6, 3, 2, 1)\r\n",
    "\r\n",
    "gridsizes <- c(4, 8, 16, 32)\r\n",
    "\r\n",
    "# 06 Build grid of models for looping ####\r\n",
    "gridOfModels <-\r\n",
    "    expand.grid(modelVersions, gridsizes, datasets, recordsShrinkFactors)\r\n",
    "\r\n",
    "names(gridOfModels) <-\r\n",
    "    c(\"modelVersions\", \"gridsizes\", \"datasets\", \"recordsShrinkFactors\")\r\n",
    "\r\n",
    "registerDoParallel(detectCores() - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07 Start looping ####\r\n",
    "for (model in seq_len(nrow(gridOfModels))\r\n",
    ") {\r\n",
    "    modelVersion <<- gridOfModels$modelVersions[model]\r\n",
    "    gridsize <<- gridOfModels$gridsizes[model]\r\n",
    "    dataset <<- gridOfModels$datasets[model]\r\n",
    "    recordsShrinkFactor <<- gridOfModels$recordsShrinkFactors[model]\r\n",
    "\r\n",
    "    modelParameters <<- paste0(\r\n",
    "        \"modelVersion\", modelVersion,\r\n",
    "        \"_gridsize\", gridsize,\r\n",
    "        \"_dataset\", dataset,\r\n",
    "        \"_shrink\", recordsShrinkFactor\r\n",
    "    )\r\n",
    "\r\n",
    "    newExportPath <<- paste0(paste0(originalExportPath, modelParameters, \"/\"))\r\n",
    "    \r\n",
    "    dir.create(newExportPath)\r\n",
    "    \r\n",
    "    exportPath <<- newExportPath\r\n",
    "\r\n",
    "    cat(\"\\n\\n\\nWORKING ON:\\n\", modelParameters, \"\\n\\n\\n\")\r\n",
    "\r\n",
    "    # 08 Subsetting variables ####\r\n",
    "    if (dataset == \"ALL\") {\r\n",
    "        dataForModel <<- allDataForModel1and2\r\n",
    "    } else if (dataset == \"SelectedVars\") {\r\n",
    "        dataForModel <<- selectedPredictorVarsDataForModel1and2\r\n",
    "    }\r\n",
    "\r\n",
    "    # 09 Dropping asking price predictor if model 2 ###\r\n",
    "    if (modelVersion == 2) {\r\n",
    "        dataForModel <<-\r\n",
    "            dataForModel %>%\r\n",
    "            select(-contains(\"askingPrice\"))\r\n",
    "    }\r\n",
    "\r\n",
    "    # 10 Shrinking number of records ####\r\n",
    "    sampleSize <<- floor(nrow(dataForModel) / recordsShrinkFactor)\r\n",
    "\r\n",
    "    set.seed(412)\r\n",
    "    dataForModel <<- dataForModel[sample(nrow(dataForModel), sampleSize), ]\r\n",
    "\r\n",
    "    # 11 Splitting data ####\r\n",
    "    set.seed(412)\r\n",
    "    dataSplit <<- initial_split(dataForModel)\r\n",
    "    dataTraining <<- training(dataSplit)\r\n",
    "    dataTesting <<- testing(dataSplit)\r\n",
    "\r\n",
    "    # 12 Make 'recipe' for model ####\r\n",
    "    dataRecipe <<-\r\n",
    "        recipe(dataTraining) %>%\r\n",
    "        update_role(!!!syms(names(dataTraining)), new_role = \"predictor\") %>%\r\n",
    "        update_role(!!!syms(outcomeVarModel1and2), new_role = \"outcome\")\r\n",
    "\r\n",
    "    # 13 Make a 'prepared' object ####\r\n",
    "    dataPrep <<- prep(dataRecipe)\r\n",
    "\r\n",
    "    # 14 'Bake' the prepared object ####\r\n",
    "    dataBaked <<- bake(dataPrep, new_data = NULL)\r\n",
    "\r\n",
    "    # 15 Specify 'ranger', hyperparameter tuning, grid specifications ####\r\n",
    "    tuneSpec <<-\r\n",
    "        rand_forest(\r\n",
    "            mode = \"regression\",\r\n",
    "            mtry = tune(),\r\n",
    "            trees = tune(),\r\n",
    "            min_n = tune()\r\n",
    "        ) %>%\r\n",
    "        set_engine(\"ranger\")\r\n",
    "\r\n",
    "    tuneGrid <<-\r\n",
    "        grid_latin_hypercube(\r\n",
    "            finalize(mtry(), dataTraining),\r\n",
    "            trees(),\r\n",
    "            min_n(),\r\n",
    "            size = gridsize\r\n",
    "        )\r\n",
    "\r\n",
    "    tuneWorkflow <<-\r\n",
    "        workflow() %>%\r\n",
    "        add_recipe(dataRecipe) %>%\r\n",
    "        add_model(tuneSpec)\r\n",
    "\r\n",
    "    # 16 Specify cross-validation data ####\r\n",
    "    set.seed(412)\r\n",
    "    dataFolds <<- vfold_cv(dataTraining)\r\n",
    "\r\n",
    "    # 17 Do initial exploratory tuning - this will take a long time ####\r\n",
    "    t1 <<- Sys.time()\r\n",
    "    tuneResults <<-\r\n",
    "        tune_grid(\r\n",
    "            tuneWorkflow,\r\n",
    "            resamples = dataFolds,\r\n",
    "            grid = tuneGrid,\r\n",
    "            control = control_grid(save_pred = TRUE)\r\n",
    "        )\r\n",
    "    t2 <<- Sys.time()\r\n",
    "    cat(\"Time elapsed with parameters\", modelParameters, \":\\n\")\r\n",
    "    print(t2 - t1)\r\n",
    "\r\n",
    "    # 18 save the results ####\r\n",
    "\r\n",
    "    mySave(tuneResults)\r\n",
    "\r\n",
    "    # 19 Visualize results ####\r\n",
    "    plotGridRmse <-\r\n",
    "        tuneResults %>%\r\n",
    "        collect_metrics() %>%\r\n",
    "        filter(.metric == \"rmse\") %>%\r\n",
    "        select(mean, mtry:min_n) %>%\r\n",
    "        pivot_longer(mtry:min_n,\r\n",
    "            values_to = \"value\",\r\n",
    "            names_to = \"parameter\"\r\n",
    "        ) %>%\r\n",
    "        ggplot(aes(value, mean, color = parameter)) +\r\n",
    "        geom_point(alpha = 0.8, show.legend = F) +\r\n",
    "        facet_wrap(~parameter, scales = \"free_x\") +\r\n",
    "        labs(x = NULL, y = \"RMSE\", title = modelParameters)\r\n",
    "\r\n",
    "    mySave(plotGridRmse)\r\n",
    "\r\n",
    "    plotGridRsq <-\r\n",
    "        tuneResults %>%\r\n",
    "        collect_metrics() %>%\r\n",
    "        filter(.metric == \"rsq\") %>%\r\n",
    "        select(mean, mtry:min_n) %>%\r\n",
    "        pivot_longer(mtry:min_n,\r\n",
    "            values_to = \"value\",\r\n",
    "            names_to = \"parameter\"\r\n",
    "        ) %>%\r\n",
    "        ggplot(aes(value, mean, color = parameter)) +\r\n",
    "        geom_point(alpha = 0.8, show.legend = F) +\r\n",
    "        facet_wrap(~parameter, scales = \"free_x\") +\r\n",
    "        labs(x = NULL, y = \"RSQ\", title = modelParameters)\r\n",
    "\r\n",
    "    mySave(plotGridRsq)\r\n",
    "\r\n",
    "    print(show_best(tuneResults, \"rmse\"))\r\n",
    "    print(show_best(tuneResults, \"rsq\"))\r\n",
    "\r\n",
    "    # 20 Finalize model ####\r\n",
    "    bestRmse <<- select_best(tuneResults, \"rmse\")\r\n",
    "\r\n",
    "    finalModel <<-\r\n",
    "        finalize_model(tuneSpec, bestRmse)\r\n",
    "\r\n",
    "    # 21 Looking at variable importance in the model ####\r\n",
    "    plotTopPredictors <-\r\n",
    "        finalModel %>%\r\n",
    "        set_engine(\"ranger\", importance = \"permutation\") %>%\r\n",
    "        fit(sellingPriceRawData ~ .,\r\n",
    "            data = dataBaked\r\n",
    "        ) %>%\r\n",
    "        vip(geom = \"col\") +\r\n",
    "        labs(title = modelParameters)\r\n",
    "\r\n",
    "    mySave(plotTopPredictors)\r\n",
    "\r\n",
    "    # 22 Get the final fit model for getting predictions ####\r\n",
    "    set.seed(412)\r\n",
    "    finalFit <<- fit(finalModel, sellingPriceRawData ~ ., dataTraining)\r\n",
    "\r\n",
    "    mySave(finalFit)\r\n",
    "\r\n",
    "    # 23 Get the final train/test results for evaluating your model ####\r\n",
    "    finalResults <<- last_fit(finalModel, sellingPriceRawData ~ ., dataSplit)\r\n",
    "\r\n",
    "    mySave(finalResults)\r\n",
    "\r\n",
    "    # 24 Get metrics from train-test results ####\r\n",
    "    finalMetrics <<- collect_metrics(finalResults)\r\n",
    "\r\n",
    "    mySave(finalMetrics)\r\n",
    "\r\n",
    "    # 25 Visualize residuals ####\r\n",
    "    plotResiduals <-\r\n",
    "        finalResults %>%\r\n",
    "        collect_predictions() %>%\r\n",
    "        ggplot(aes(sellingPriceRawData, .pred)) +\r\n",
    "        geom_abline(slope = 1, lty = 2, color = \"gray50\", alpha = 0.5) +\r\n",
    "        geom_point(alpha = 0.6, color = \"midnightblue\") +\r\n",
    "        coord_fixed() +\r\n",
    "        labs(title = modelParameters)\r\n",
    "\r\n",
    "    mySave(plotResiduals)\r\n",
    "\r\n",
    "    # 26 Get data for confidence interval ####\r\n",
    "    dataForConfInterval <- dataTesting\r\n",
    "\r\n",
    "    dataForConfInterval[[\"predictions\"]] <-\r\n",
    "        predict(finalFit, new_data = dataForConfInterval)\r\n",
    "\r\n",
    "    # 27 Resaving in global scope ####\r\n",
    "    dataForConfInterval <<- dataForConfInterval\r\n",
    "\r\n",
    "    mySave(dataForConfInterval)\r\n",
    "\r\n",
    "    confIntervalData <<-\r\n",
    "        dataForConfInterval %>%\r\n",
    "        mutate(\r\n",
    "            predictions =\r\n",
    "                predict(finalFit, new_data = .),\r\n",
    "            residuals = sellingPriceRawData - predictions\r\n",
    "        ) %>%\r\n",
    "        select(predictions, sellingPriceRawData, residuals) %>%\r\n",
    "        summarize(\r\n",
    "            meanResidual = mean(residuals$.pred),\r\n",
    "            medianResidual = median(residuals$.pred),\r\n",
    "            percentile2.5 = quantile(residuals$.pred, 0.025),\r\n",
    "            percentile10 = quantile(residuals$.pred, 0.10),\r\n",
    "            percentile16 = quantile(residuals$.pred, 0.16),\r\n",
    "            percentile84 = quantile(residuals$.pred, 0.84),\r\n",
    "            percentile90 = quantile(residuals$.pred, 0.90),\r\n",
    "            percentile97.5 = quantile(residuals$.pred, 0.975)\r\n",
    "        )\r\n",
    "\r\n",
    "    print(confIntervalData)\r\n",
    "\r\n",
    "    mySave(confIntervalData)\r\n",
    "\r\n",
    "    # 28 Clean up\r\n",
    "    rm(\r\n",
    "        bestRmse, confIntervalData, dataBaked, dataFolds, dataForConfInterval,\r\n",
    "        dataForModel, dataPrep, dataRecipe, dataSplit, dataTesting, dataTraining,\r\n",
    "        finalFit, finalMetrics, finalModel, finalResults, plotGridRmse,\r\n",
    "        plotGridRsq, plotResiduals, plotTopPredictors, tuneGrid, tuneResults,\r\n",
    "        tuneSpec, tuneWorkflow, dataset, exportPath, gridsize, model,\r\n",
    "        modelVersion, newExportPath, recordsShrinkFactor, sampleSize, t1, t2\r\n",
    "    )\r\n",
    "    \r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 28 Celebrate ####\r\n",
    "cat(\"\\n\\nGreat job, you finished building all those models!\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c7b55d8a54839fac4c6fbf997eb77542bf11c3b22de64efbb859a080aa358fb"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}