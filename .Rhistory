setdiff(engnrdNumericVars, engnrdNumericAggByCat)
numericVarsForDensityPlots <-
sort(c(originalNumericVars, engnrdNumericNotAggByCat))
# 07 Cat variables for violin, strip, and conditional density plots ####
engnrdFactorVars <-
intersect(engnrdVars, allFactorVars)
catVarsForPlots <-
engnrdFactorVars %>%
str_subset("Ohe", negate = T) %>%
str_subset("monthSoldEnglish", negate = T) %>%
str_subset("Generalized|Sold") %>%
c("cityRawData", .)
oheVars <-
engnrdFactorVars %>%
str_subset("Ohe")
# 08 Con variables for violin, strip, and conditional density plots ####
engnrdNonhalfNotDropped <-
engnrdNumericNotAggByCat %>%
str_subset("floor") %>%
str_subset("Nonhalf", negate = T)
conVarsForPlots <-
str_subset(engnrdNumericNotAggByCat, "Imputed") %>%
setdiff(engnrdNonhalfNotDropped) %>%
sort %>%
c("sellingPriceRawData", .)
# 09 Variables for heatmaps ####
discreteVarsForHeatmaps <-
str_subset(conVarsForPlots, "kvm|room|floor") %>%
str_subset("avgift|runningCosts", negate = T) %>%
c(catVarsForPlots, "yearSoldRawData")
conVarsForAggs <-
engnrdNumericVars %>%
str_subset("Mean|Median|Sum") %>%
str_subset("Interpolated")
catVarsForAggPlots <-
catVarsForPlots %>%
str_subset(catVarsForTimeSeriesAnalysis)
# 10 All complete data ####
allCompleteData <-
preprocessedAllData %>%
.[ , colSums(is.na(.)) == 0]
mySaveVarGroups(outFolderDataForModel1, allCompleteData)
# 11 Agg columns that will be kept later ####
aggCols <-
allCompleteData %>%
names %>%
str_subset("Mean|Median|Sum") %>%
str_subset("Interpolated")
# 12 Outcome variable ####
outcomeVar <- "sellingPriceRawData"
mySaveVarGroups(outFolderDataForModel1, outcomeVar)
# 13 Drop intermediate calculated columns ####
# PAUSED HERE - still trying to figure out why unable to engineer agg 15 aggCols features for novel data plugged in
allPredictors <- #
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd|Mean|Median|Sum',
negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData', aggCols) %>%
sort
allPredictors <- #
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd', negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData') %>%
sort
allPredictorsOld <- #
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd', negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData') %>%
sort
# 13 Drop intermediate calculated columns ####
# PAUSED HERE - still trying to figure out why unable to engineer agg 15 aggCols features for novel data plugged in
allPredictors <- # 1127
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd|Mean|Median|Sum',
negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData', aggCols) %>%
sort
setdiff(allPredictorsOld, allPredictors)
# 01 Ensure all pkgs in this script are installed ####
pkgs <-
c(
"sqldf"
, "lubridate"
, "RcppRoll"
, "caret"
, 'openxlsx'
)
activatePkgs(pkgs)
# 02 load latest compiled data ####
compiledData <-
paste0(
outputFolderCompiled
, list.files(outputFolderCompiled) %>%
.[length(.)]) %>%
readRDS
# 03 Bring in my data to predict ####
newData <- read.xlsx("06_inputs/i02_inputForPredictions.xlsx")
compiledData <-
rbind(newData, compiledData)
# testing my new function
compiledData %<>% .[1:20, ]
# 04 Sourcing the macro to do all the feature engineering ####
source('11_macros/m01_engineerMyFeatures.r')
compiledData$cityMeanSellingPrice7DaysAgoInterpolatedPsdData %>% head
compiledData$cityMeanSellingPriceThisDatePsdData %>% head
compiledData$cityMeanSellingPriceThisDateInterpolatedPsdData %>% head
# 13 Drop intermediate calculated columns ####
# PAUSED HERE - still trying to figure out why unable to engineer agg 15 aggCols features for novel data plugged in
allPredictors <- # 1127
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd|Mean|Median|Sum',
negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData', aggCols) %>%
sort
allPredictorsOld <- #
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd', negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData') %>%
sort
allPredictors %>% names %>% str_subset('DaysAgo') %>% head
allPredictors %>% names %>% str_subset('ays') %>% head
allPredictors %>% str_subset('DaysAgo') %>% head
# Purpose: Preparing variable groups for building model 1
# Author: David Gray Lassiter, PhD
# Date: 2020-sep-22
# Version:
# 01 Ensure all pkgs in this script are installed ####
pkgs <-
c(
)
activatePkgs(pkgs)
# 02 load latest preprocessed data ####
preprocessedAllData <-
paste0(
outFolderPreprocessedAllData,
list.files(outFolderPreprocessedAllData) %>%
.[length(.)]
) %>%
readRDS()
# 03 Testing data classes ####
allNumericVars <-
preprocessedAllData %>%
select_if(is.numeric) %>%
names
allFactorVars <-
preprocessedAllData %>%
select_if(is.factor) %>%
names()
allOtherVars <-
preprocessedAllData %>%
select(!c(allNumericVars, allFactorVars)) %>%
names
if (length(allOtherVars) > 0) message("Some variables are misclassified")
# 06 Variables for density plots ####
allVars <-
names(preprocessedAllData)
originalVars <-
str_subset(allVars, "RawData")
originalNumericVars <-
intersect(originalVars, allNumericVars)
engnrdVars <-
str_subset(allVars, "PsdData")
engnrdNumericVars <-
intersect(engnrdVars, allNumericVars)
engnrdNumericAggByCat <-
str_subset(engnrdNumericVars, "Mean|Median|Sum")
engnrdNumericNotAggByCat <-
setdiff(engnrdNumericVars, engnrdNumericAggByCat)
numericVarsForDensityPlots <-
sort(c(originalNumericVars, engnrdNumericNotAggByCat))
# 07 Cat variables for violin, strip, and conditional density plots ####
engnrdFactorVars <-
intersect(engnrdVars, allFactorVars)
catVarsForPlots <-
engnrdFactorVars %>%
str_subset("Ohe", negate = T) %>%
str_subset("monthSoldEnglish", negate = T) %>%
str_subset("Generalized|Sold") %>%
c("cityRawData", .)
oheVars <-
engnrdFactorVars %>%
str_subset("Ohe")
# 08 Con variables for violin, strip, and conditional density plots ####
engnrdNonhalfNotDropped <-
engnrdNumericNotAggByCat %>%
str_subset("floor") %>%
str_subset("Nonhalf", negate = T)
conVarsForPlots <-
str_subset(engnrdNumericNotAggByCat, "Imputed") %>%
setdiff(engnrdNonhalfNotDropped) %>%
sort %>%
c("sellingPriceRawData", .)
# 09 Variables for heatmaps ####
discreteVarsForHeatmaps <-
str_subset(conVarsForPlots, "kvm|room|floor") %>%
str_subset("avgift|runningCosts", negate = T) %>%
c(catVarsForPlots, "yearSoldRawData")
conVarsForAggs <-
engnrdNumericVars %>%
str_subset("Mean|Median|Sum") %>%
str_subset("Interpolated")
catVarsForAggPlots <-
catVarsForPlots %>%
str_subset(catVarsForTimeSeriesAnalysis)
# 10 All complete data ####
allCompleteData <-
preprocessedAllData %>%
.[ , colSums(is.na(.)) == 0]
mySaveVarGroups(outFolderDataForModel1, allCompleteData)
# 11 Agg columns that will be kept later ####
aggCols <-
allCompleteData %>%
names %>%
str_subset("Mean|Median|Sum") %>%
str_subset("Interpolated")
# 12 Outcome variable ####
outcomeVar <- "sellingPriceRawData"
mySaveVarGroups(outFolderDataForModel1, outcomeVar)
# 13 Drop intermediate calculated columns ####
allPredictors <- # 1127
allCompleteData %>%
names %>%
str_subset('RawData|CleanedString|English|floorImputed|ConsolidatedPsd|Mean|Median|Sum',
negate = T) %>%
union_all('cityCleanedStringPsdData', 'yearSoldRawData', aggCols) %>%
sort
mySaveVarGroups(outFolderDataForModel1, allPredictors)
# 13 Drop one-hot encoding columns ####
manyPredictors <-
allPredictors %>%
str_subset('Ohe', negate = T)
mySaveVarGroups(outFolderDataForModel1, manyPredictors)
# 14 Drop columns that did aggregated calculations ####
fewPredictors <-
manyPredictors %>%
str_subset('Mean|Median|Sum', negate = T)
mySaveVarGroups(outFolderDataForModel1, fewPredictors)
# 01 Ensure all pkgs in this script are installed ####
install.packages('here')
install.packages('tidyverse')
install.packages('tidymodels')
install.packages('ranger')
install.packages("doParallel")
install.packages("vip")
library('here')
library('tidyverse')
library('tidymodels')
library('ranger')
library('doParallel')
library('vip')
# 02 Set paths ####
setwd(here())
importPath <- '07_outputs/06_dataForModel1/'
originalExportPath <- '07_outputs/07_buildingModel1/01_localExportData/'
exportPath <- originalExportPath
# 03 Load data ####
allCompleteData <- readRDS(paste0(importPath, "allCompleteData"))
outcomeVar <- readRDS(paste0(importPath, "outcomeVar"))
allPredictors <- readRDS(paste0(importPath, "allPredictors"))
manyPredictors <- readRDS(paste0(importPath, "manyPredictors"))
fewPredictors <- readRDS(paste0(importPath, "fewPredictors"))
# 04 My save function ####
# I define the function in place in case I move this script to the cloud
# and will not be able to refer to local functions
mySave <- function(object) {
objectName <- deparse(substitute(object))
saveRDS(
object,
paste0(exportPath, objectName)
)
}
testSave <- 1 + 1
mySave(testSave)
rm(testSave)
# 05 Set parameters for model-building ####
modelVersions <- c("lackAskingPrice", "haveAskingPrice")
gridsizes <- c(
2 # For testing only
# 4, 16, 32
)
datasets <- c("fewVars", "manyVars", "allVars")
recordsShrinkFactors <- c(
100 # For testing only
# 50, 12, 3, 1
)
# 06 Build grid of models for looping ####
gridOfModels <-
expand.grid(modelVersions, gridsizes, datasets, recordsShrinkFactors)
names(gridOfModels) <-
c("modelVersions", "gridsizes", "datasets", "recordsShrinkFactors")
registerDoParallel(detectCores() - 2)
# Tests
cat("workers:", getDoParWorkers())
cat("gridOfModels:")
modelVersions
gridsizes
datasets
recordsShrinkFactors
expand.grid(modelVersions, gridsizes, datasets, recordsShrinkFactors)
print(gridOfModels[1:6, ])
print(gridOfModels[1:10, ])
cat('head of names with "city" in allCompleteData:')
allCompleteData[, allPredictors] %>%
names() %>%
str_subset("city") %>%
head() %>%
print()
# 07 Start looping ####
for (model in
1:2 #For testing only
# n : nrow(gridOfModels) # Will set this diff for local and cloud
# seq_len(nrow(gridOfModels))
)
{
modelVersion <<- gridOfModels$modelVersions[model]
gridsize <<- gridOfModels$gridsizes[model]
dataset <<- gridOfModels$datasets[model]
recordsShrinkFactor <<- gridOfModels$recordsShrinkFactors[model]
modelParameters <<- paste0(
"m", model,
"_", modelVersion,
"_gridsize", gridsize,
"_", dataset,
"_shrink", recordsShrinkFactor
)
newExportPath <<- paste0(paste0(originalExportPath, modelParameters, "/"))
dir.create(newExportPath)
exportPath <<- newExportPath
cat("\n\n\nWORKING ON:\n", modelParameters, "\n\n\n")
# 08 Subsetting variables ####
if (dataset == 'fewVars') {
varsForModel <<- fewPredictors
} else if (dataset == 'manyVars') {
varsForModel <- manyPredictors
} else if (dataset == 'allVars') {
varsForModel <<- allPredictors
}
# 09 Dropping asking price predictor if model 2 ###
if (modelVersion == 'lackAskingPrice') {
varsForModel <<-
setdiff(varsForModel, 'askingPrice')
}
dataForModel <-
allCompleteData[, c(outcomeVar, varsForModel)]
# 10 Shrinking number of records ####
sampleSize <<- floor(nrow(dataForModel) / recordsShrinkFactor)
set.seed(412)
dataForModel <<- dataForModel[sample(nrow(dataForModel), sampleSize), ]
# 11 Splitting data ####
set.seed(412)
dataSplit <<- initial_split(dataForModel)
dataTraining <<- training(dataSplit)
dataTesting <<- testing(dataSplit)
# 12 Make 'recipe' for model ####
dataRecipe <<-
recipe(dataTraining) %>%
update_role(!!!syms(names(dataTraining)), new_role = "predictor") %>%
update_role(!!!syms(outcomeVar), new_role = "outcome")
# 13 Make a 'prepared' object ####
dataPrep <<- prep(dataRecipe)
# 14 'Bake' the prepared object ####
dataBaked <<- bake(dataPrep, new_data = NULL)
# 15 Specify 'ranger', hyperparameter tuning, grid specifications ####
tuneSpec <<-
rand_forest(
mode = 'regression',
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger')
tuneGrid <<-
grid_latin_hypercube(
finalize(mtry(), dataTraining),
trees(),
min_n(),
size = gridsize
)
tuneWorkflow <<-
workflow() %>%
add_recipe(dataRecipe) %>%
add_model(tuneSpec)
# 16 Specify cross-validation data ####
set.seed(412)
dataFolds <<- vfold_cv(dataTraining)
# 17 Do initial exploratory tuning - this will take a long time ####
t1 <<- Sys.time()
tuneResults <<-
tune_grid(
tuneWorkflow,
resamples = dataFolds,
grid = tuneGrid,
control = control_grid(save_pred = TRUE)
)
t2 <<- Sys.time()
cat("Time elapsed with parameters", modelParameters, ":\n")
print(t2 - t1)
# 18 save the results ####
print(tuneResults)
mySave(tuneResults)
# 19 Visualize results ####
plotGridRmse <-
tuneResults %>%
collect_metrics() %>%
filter(.metric == "rmse") %>%
select(mean, mtry : min_n) %>%
pivot_longer(mtry : min_n,
values_to = "value",
names_to = "parameter"
) %>%
ggplot(aes(value, mean, color = parameter)) +
geom_point(alpha = 0.8, show.legend = F) +
facet_wrap(~parameter, scales = "free_x") +
labs(x = NULL, y = "RMSE", title = modelParameters)
mySave(plotGridRmse)
plotGridRsq <-
tuneResults %>%
collect_metrics() %>%
filter(.metric == "rsq") %>%
select(mean, mtry : min_n) %>%
pivot_longer(mtry : min_n,
values_to = "value",
names_to = "parameter"
) %>%
ggplot(aes(value, mean, color = parameter)) +
geom_point(alpha = 0.8, show.legend = F) +
facet_wrap(~parameter, scales = "free_x") +
labs(x = NULL, y = "RSQ", title = modelParameters)
mySave(plotGridRsq)
print(show_best(tuneResults, "rmse"))
print(show_best(tuneResults, "rsq"))
# 20 Finalize model ####
bestRmse <<- select_best(tuneResults, "rmse")
finalModel <<-
finalize_model(tuneSpec, bestRmse)
# 21 Looking at variable importance in the model ####
plotTopPredictors <-
finalModel %>%
set_engine('ranger', importance = "permutation") %>%
fit(sellingPriceRawData ~ .,
data = dataBaked
) %>%
vip(geom = "col") +
labs(title = modelParameters)
mySave(plotTopPredictors)
# 22 Get the final fit model for getting predictions ####
set.seed(412)
finalFit <<- fit(finalModel, sellingPriceRawData ~., dataTraining)
mySave(finalFit)
# 23 Get the final train/test results for evaluating your model ####
finalResults <<- last_fit(finalModel, sellingPriceRawData ~., dataSplit)
mySave(finalResults)
# 24 Get metrics from train-test results ####
finalMetrics <<- collect_metrics(finalResults)
print(finalMetrics)
mySave(finalMetrics)
# 25 Visualize residuals ####
plotResiduals <-
finalResults %>%
collect_predictions() %>%
ggplot(aes(sellingPriceRawData, .pred)) +
geom_abline(slope = 1, lty = 2, color = "gray50", alpha = 0.5) +
geom_point(alpha = 0.6, color = "midnightblue") +
coord_fixed() +
labs(title = modelParameters)
mySave(plotResiduals)
# 26 Get data for confidence interval ####
dataForConfInterval <- dataTesting
dataForConfInterval[['predictions']] <-
predict(finalFit, new_data = dataForConfInterval)
# 27 Resaving in global scope ####
dataForConfInterval <<- dataForConfInterval
mySave(dataForConfInterval)
confIntervalData <<-
dataForConfInterval %>%
mutate(
predictions =
predict(finalFit, new_data = .),
residuals = sellingPriceRawData - predictions) %>%
select(predictions, sellingPriceRawData, residuals) %>%
summarize(meanResidual = mean(residuals$.pred),
medianResidual = median(residuals$.pred),
percentile2.5 = quantile(residuals$.pred, 0.025),
percentile10 = quantile(residuals$.pred, 0.10),
percentile16 = quantile(residuals$.pred, 0.16),
percentile84 = quantile(residuals$.pred, 0.84),
percentile90 = quantile(residuals$.pred, 0.90),
percentile97.5 = quantile(residuals$.pred, 0.975)
)
print(confIntervalData)
mySave(confIntervalData)
# 28 Clean up
rm(bestRmse, confIntervalData, dataBaked, dataFolds, dataForConfInterval,
dataForModel, dataPrep, dataRecipe, dataSplit, dataTesting, dataTraining,
finalFit, finalMetrics, finalModel, finalResults, plotGridRmse,
plotGridRsq, plotResiduals, plotTopPredictors, tuneGrid, tuneResults,
tuneSpec, tuneWorkflow, dataset, exportPath, gridsize, model,
modelVersion, newExportPath, recordsShrinkFactor, sampleSize, t1, t2)
}
allPredictors %>% str_subset('city')
allPredictors %>% str_subset('city') %>% Mean
allPredictors %>% str_subset('city') %>% str_subset('Mean')
# 29 Celebrate ####
registorDoSEQ()
# 29 Celebrate ####
registerDoSEQ()
